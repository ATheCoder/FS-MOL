{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "FS_MOL_CHECKOUT_PATH = os.path.abspath('../')\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from fs_mol.clip_like import FingerprintEncoder\n",
    "from fs_mol.data.clip_dataset import CLIPDataset\n",
    "from fs_mol.modules.gat import GAT_GraphEncoder, TrainConfig\n",
    "from fs_mol.data.clip_fewshot_dataset import FSMOL\n",
    "from fs_mol.models.protonet import calculate_mahalanobis_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CLIPDataset(root='/', raw_file_path='/FS-MOL/train_raw_mols.pt', dest_file_name='/FS-MOL/train_preprocessed_mols.pt')\n",
    "# valid_dataset = CLIPDataset(root='/', raw_file_path='/FS-MOL/valid_raw_mols.pt', dest_file_name='/FS-MOL/valid_preprocessed_mols.pt')   \n",
    "valid_dataset = torch.load('/FS-MOL/valid_none_dup_processed.pt')\n",
    "# fewshot_dataset = FSMOL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 216827\n",
      "Valid Dataset Size: 9574\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Dataset Size: {len(train_dataset)}')\n",
    "print(f'Valid Dataset Size: {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = TrainConfig()\n",
    "\n",
    "config.graph_encoder_num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, drop_last=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg_hist = PNAConv.get_degree_histogram(loader=loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PNA_GraphEncoder(nn.Module):\n",
    "#     def __init__(self, deg_hist) -> None:\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.batch_size = 32\n",
    "        \n",
    "#         self.gnn = PNA(\n",
    "#             in_channels=32,\n",
    "#             hidden_channels=128,\n",
    "#             num_layers=10,\n",
    "#             out_channels=128,\n",
    "#             edge_dim=1,\n",
    "#             aggregators=['sum', 'mean', 'max', 'std'],\n",
    "#             scalers=['amplification', 'attenuation'],\n",
    "#             deg=deg_hist\n",
    "#         )\n",
    "        \n",
    "#         self.readout = CombinedGraphReadout(\n",
    "#             node_dim=128,\n",
    "#             out_dim=512,\n",
    "#             num_heads=12,\n",
    "#             head_dim=64,\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, batch):\n",
    "#         edge_index, edge_attr = to_undirected(batch.edge_index, batch.edge_attr, 32)\n",
    "#         node_features = self.gnn(batch.x, edge_index, edge_attr=edge_attr)\n",
    "#         return self.readout(node_features, batch.batch, self.batch_size)\n",
    "    \n",
    "# model = PNA_GraphEncoder(deg_hist=deg_hist).cuda()\n",
    "\n",
    "# model(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2696,  0.4219,  0.9399,  ...,  0.2700, -0.9707, -0.3564],\n",
       "        [-0.3516,  0.2873,  0.7667,  ...,  0.1339, -0.9777, -0.4234],\n",
       "        [-0.3090,  0.3072,  0.8088,  ...,  0.1545, -0.7782, -0.4980],\n",
       "        ...,\n",
       "        [-0.3513,  0.3004,  0.7584,  ...,  0.3638, -0.6603, -0.4933],\n",
       "        [-0.3678,  0.4369,  0.8178,  ...,  0.3691, -0.8012, -0.5012],\n",
       "        [-0.3207,  0.3194,  0.8370,  ...,  0.2484, -0.8435, -0.3207]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAT_GraphEncoder(config).to('cuda')\n",
    "\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mathecoder\u001b[0m (\u001b[33mdest\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea328d5d0184a3d8f7448724bf393b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666892743334453, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/FS-MOL/wandb/run-20230318_152250-s82hhnym</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dest/FS-Mol/runs/s82hhnym\" target=\"_blank\">olive-rain-101</a></strong> to <a href=\"https://wandb.ai/dest/FS-Mol\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | graph_encoder       | GAT_GraphEncoder   | 1.0 M \n",
      "1 | fingerprint_encoder | FingerprintEncoder | 2.6 M \n",
      "2 | acc_metric          | BinaryAccuracy     | 0     \n",
      "-----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.513    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def0fb7ffc174a3cb79dcc00d50f8f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea697bc6de24f048e41f6628ae6af0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455ac02154c242f89853cd3ebc74d649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05509274c15447694af5ba94ce395e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca181e710a03443bb2157e0cca1ddec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db921f15b90647b288d89c78e68c826f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb8de39c78479db65d09875d47d652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31f2b1012214e02bee9f2a15c71adfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8e3ca91c3543e0bb2bf5baa439c00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1932c9565b114f21be21bc300c58d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0155203c66e7438b9e8e764eb62f5bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ef611b392b4a7ba24b6b43c083a8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc851f701e949788fa3f82493cec174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875da8509fe14995b36588511a02f4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63df2e888efe4de5ae57d9667b53d335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae1863e6dab4464b7537362d0e586c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53db029618c429aac215ae2e198c911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fe7594ee7248e382e32adcd58a6fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dfe87acaab4270b6bfba648dd48988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f1e85a6b0248ad9393675828041b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035d09f7b19f4ba4ba84c3aa1e4ca681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b066d555741a46079e2ade4dfd035ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc8183e09444aeab6b06a10b4e999de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03300caa2d18417db962acc28e03cba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50e7b40650a41d6b4ba824f674eb016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041a81574bde4e69b4f90c5a6ed4d09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d518be1edf8b456e86605edcae4d44e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c55a501f1764128b1c4b39c876c7618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bec633f12c4c638f1af29e94e801da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from wandb import wandb\n",
    "from torchmetrics import Accuracy\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "\n",
    "valid_step = 0\n",
    "\n",
    "class ClipLike(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temp = 0.1\n",
    "        # self.graph_encoder = PyG_GraphFeatureExtractor(GraphFeatureExtractorConfig())\n",
    "        self.graph_encoder = GAT_GraphEncoder(config)\n",
    "        self.fingerprint_encoder = FingerprintEncoder(2048, config.fingerprint_encoder_hidden_dim, config.fingerprint_encoder_output_dim, config.fingerprint_encoder_dropout)\n",
    "        self.acc_metric = Accuracy(task='binary')\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        encoded_graphs = self.graph_encoder(batch)\n",
    "        encoded_fingerprints = self.fingerprint_encoder(batch.fingerprint.reshape(-1, 2048).to(torch.float32))\n",
    "        # TODO: Check the OpenAI's Codebase on CLIP and make sure this is right.\n",
    "        logits = encoded_graphs @ encoded_fingerprints.T / self.temp\n",
    "        \n",
    "        current_batch_size = encoded_graphs.shape[0]\n",
    "        \n",
    "        targets = torch.eye(current_batch_size).cuda() / self.temp\n",
    "        \n",
    "        loss = F.cross_entropy(logits, targets, reduction=\"none\")\n",
    "        \n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, batch_size=current_batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        encoded_graphs = self.graph_encoder(batch)\n",
    "        encoded_fingerprints = self.fingerprint_encoder(batch.fingerprint.reshape(-1, 2048).to(torch.float32))\n",
    "        # TODO: Check the OpenAI's Codebase on CLIP and make sure this is right.\n",
    "        logits = encoded_graphs @ encoded_fingerprints.T / self.temp\n",
    "        \n",
    "        current_batch_size = encoded_graphs.shape[0]\n",
    "        \n",
    "        targets = torch.eye(current_batch_size).cuda() / self.temp\n",
    "        \n",
    "        loss = F.cross_entropy(logits, targets, reduction=\"none\")\n",
    "        \n",
    "        loss = loss.mean()\n",
    "        self.log('valid_loss', loss, batch_size=current_batch_size)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs) -> None:\n",
    "        fewshot_dataset = FSMOL()\n",
    "        mean_acc = 0\n",
    "        for support_set, query_set in fewshot_dataset:\n",
    "            support_labels = [mol.bool_label for mol in support_set]\n",
    "            query_labels = [mol.bool_label for mol in query_set]\n",
    "            \n",
    "            encoded_support_graphs = self.graph_encoder(Batch.from_data_list(support_set).to('cuda'))\n",
    "            encoded_query_graphs = self.graph_encoder(Batch.from_data_list(query_set).to('cuda'))\n",
    "            \n",
    "            logits = calculate_mahalanobis_logits(encoded_support_graphs, torch.tensor(support_labels, device=torch.device('cuda')), encoded_query_graphs, torch.device('cuda'))\n",
    "            porbabilities = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            predictions = torch.argmax(porbabilities, dim=1)\n",
    "            \n",
    "            acc = self.acc_metric(predictions, torch.tensor(query_labels, device=torch.device('cuda')))\n",
    "            mean_acc += acc\n",
    "            \n",
    "        wandb.log({'fewshot_acc': mean_acc / len(fewshot_dataset)})\n",
    "            \n",
    "            \n",
    "    \n",
    "wandb.init(config=config)\n",
    "model = ClipLike()\n",
    "wandb.watch(model, log='all')\n",
    "    \n",
    "trainer = pl.Trainer(logger=WandbLogger(), accelerator='gpu', devices=1, max_epochs=100)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
